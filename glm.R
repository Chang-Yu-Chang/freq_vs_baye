#' Compare glm between glmmTMB and brms
#' Simulate
#' 0. linear
#' 1. logistic
#' 2. poisson
#' 3. negative binomial
#' 4. zero inflated poisson
#' 5. zero inflated negative binomial

library(tidyverse)
library(easystats)
library(glmmTMB)
library(brms)

# Simulation ----
set.seed(123)
n_total <- 200

## Predictor
X <- rnorm(n_total, 0, 1) # predictor
eta <- 1 + 0.8 * X # Linear predictor

## 0. Linear
Y <- eta + rnorm(n_total, 0, 1) # sigma

## 1. Logistic / Bernoulli. The link function is logistic
Y1 <- rbinom(n_total, 1, plogis(eta))

## 2. Poisson
Y2 <- rpois(n_total, lambda = exp(eta))

## 3. Negative binomial
# Set a high dispersion parameter to reduce randomness generated by NB sampling
k = 10 # dispersion parameter k. var(NB) = mu + mu^2/k
Y3 <- rnbinom(n_total, mu = exp(eta), size = k)

## 4. Zero-inflated poisson
p_zero <- 0.2 # probability of zero inflation
inflate <- rbinom(n_total, size = 1, prob = 1-p_zero)
counts <- rpois(n_total, lambda = exp(eta))
Y4 <- counts*inflate

## 5. Zero-inflated negative binomial
counts <- rnbinom(n_total, mu = exp(eta), size = k)
Y5 <- counts * inflate

##
tb <- tibble(X = X, Y = Y, Y1 = Y1, Y2 = Y2, Y3 = Y3, Y4 = Y4, Y5 = Y5)
tb %>%
    pivot_longer(-X) %>%
    ggplot() +
    geom_histogram(aes(x = value)) +
    facet_wrap(~name, scales = "free") +
    theme_bw()

# Examples on NB ----
## Frequentist
mod3 <- glmmTMB(Y3 ~ X, data = tb, family = nbinom2)
summary(mod3)

# Prediction at the response scale. There are three ways to do it
predict(mod3, type = "link") # prediction at the latent scale
exp(predict(mod3)) # predict at the latent scale and apply the inversed link function
fitted(mod3) # predicted at the response scale
predict(mod3, type = "response") # predicted at the response scale

# Residuals. Two ways to do it
resid(mod3)
Y3 - exp(predict(mod3)) # residual is at the latent scale

# pseudo R2. This assumes that the residuals are normally distributed
## Based on variance of residuals that reduce the explanation of total variance
var_res <- var(Y3 - predict(mod3, type = "response")) # residual variance at the response scale
var_tot <- var(Y3) # total variance in the observation
1 - var_res/var_tot

## Bayesian
mod3_baye <- brm(Y3 ~ X, data = tb, family = negbinomial, chains = 2, cores = 2, iter = 10000, thin = 10, seed = 123, control = list(adapt_delta = 0.95))
pp_check(mod3_baye) # posterior prediction checks
as_draws_df(mod3_baye)$shape %>% median # estimated dispersion parameter

# Variance components
pfit <- posterior_epred(mod3_baye) # fitted values (mu). The same as posterior_linpred(mod3_baye, transform = T)
var_fit_samples <- apply(pfit, 1, var) # variance of fitted values (mu) across samples per draw
y <- model.response(model.frame(mod3_baye))
var_res_samples <- apply(pfit, 1, function (m) var(y-m))
# shapes <- as_draws_df(mod3_baye)$shape # Estimated shape (k) parameter
# var_res_samples <- map_dbl(1:nrow(pfit), function(i) (mean(pfit[i,] + pfit[i,]^2/shapes[i]))) # NB variance = mu + mu^2 / k per data point per draw. Average across data point to get it per draw
br2 <- var_fit_samples / ( var_fit_samples + var_res_samples)
c(mean(br2), sd(br2), quantile(br2, c(0.025, 0.975))) # this should be the same as bayes R2
bayes_R2(mod3_baye)

# Frequenstist ----
tb_freq <- tibble(name = paste0("Y", c("", 1:5)), mod = rep(list(NA), 6))

tb_freq$mod[[1]] <- glmmTMB(Y ~ X, data = tb, family = gaussian)
tb_freq$mod[[2]] <- glmmTMB(Y1 ~ X, data = tb, family = binomial(link = "logit"))
tb_freq$mod[[3]] <- glmmTMB(Y2 ~ X, data = tb, family = poisson)
tb_freq$mod[[4]] <- glmmTMB(Y3 ~ X, data = tb, family = nbinom2)
tb_freq$mod[[5]] <- glmmTMB(Y4 ~ X, data = tb, family = poisson, ziformula = ~1)
tb_freq$mod[[6]] <- glmmTMB(Y5 ~ X, data = tb, family = nbinom2, ziformula = ~1)

# Manually compute vairance based R2
## Gaussian. var(fit) / (var(fit) + sigma^2)
var_fit <- var(fitted(tb_freq$mod[[1]]))
var_fit / (var_fit + sigma(tb_freq$mod[[1]])^2)
r2(tb_freq$mod[[1]])

## Logistic. p(1-p)
### Variance-partition R² on the probability scale (intuitive)
p <- fitted(tb_freq$mod[[2]], type = "response")
var(p) / (var(p) + mean(p * (1 - p)))
### Tjur’s
p1 <- mean(p[tb$Y1 == 1])
p0 <- mean(p[tb$Y1 == 0])
p1 - p0
r2(tb_freq$mod[[2]])
### Latent scale (Nakagawa & Schielzeth)
eta <- predict(tb_freq$mod[[2]], type = "link")
var(eta) / (var(eta) + (pi^2/3))


## Poisson. var(poi) = mean(mu)
### Data (count) scale
m <- tb_freq$mod[[3]]
p <- fitted(m, type = "response")  # μ_i
var(p) / (var(p) + mean(p))

### pseudo R2
m_null <- update(m, . ~ 1) # null model
ll_full <- as.numeric(logLik(m))
ll_null <- as.numeric(logLik(m_null))
n <- nobs(m)
r2_cs <- 1 - exp((2/n) * (ll_null - ll_full)) # Cox–Snell
r2_cs
r2_coxsnell(tb_freq$mod[[3]])
dev_full <- deviance(m)
ll_sat   <- ll_full + dev_full/2 # Saturated log-likelihood for the full model
r2_nag <- r2_cs / (1 - exp((2/n) * (ll_null - ll_sat))) # Nagelkerke using saturated LL in the denominator (matches performance)
r2_nagelkerke(tb_freq$mod[[3]])

## Negative binomial
r2(tb_freq$mod[[4]])

## ZIP
r2(tb_freq$mod[[5]])
### pseudo R2
r2_nagelkerke(tb_freq$mod[[5]])
### Data (count) scale
lambda <- predict(tb_freq$mod[[5]], type = "response")     # Poisson mean (λ_i) for the count component
pi_zi  <- predict(tb_freq$mod[[5]], type = "zprob")        # zero-inflation prob (π_i)
mu     <- (1 - pi_zi) * lambda # overall mean including ZI
var_mu <- var(mu)
res_var_i <- mu + (pi_zi/(pmax(1 - pi_zi, 1e-12))) * mu^2   # per-observation ZIP variance
var_mu / (var_mu + mean(res_var_i))
### empirical.  frequentist analogue of bayes_R2
y <- model.response(model.frame(tb_freq$mod[[5]]))
var(mu) / (var(mu) + var(y - mu))


## ZINB
### pseudo R2
r2(tb_freq$mod[[6]])
### Data (count) scale
lambda <- predict(tb_freq$mod[[6]], type = "response")     # Poisson mean (λ_i) for the count component
pi_zi  <- predict(tb_freq$mod[[6]], type = "zprob")        # zero-inflation prob (π_i)
mu     <- (1 - pi_zi) * lambda # overall mean including ZI
var_mu <- var(mu)
res_var_i <- mu + (pi_zi/(pmax(1 - pi_zi, 1e-12))) * mu^2   # per-observation ZIP variance
var_mu / (var_mu + mean(res_var_i))
### empirical.  frequentist analogue of bayes_R2
m  <- tb_freq$mod[[6]]
y  <- model.response(model.frame(m))
mu <- predict(m, type = "response")   # overall mean including ZI
var(mu) / (var(mu) + var(y - mu))



# Bayesian ----
tb_baye <- tibble(name = paste0("Y", c("", 1:5)), mod = rep(list(NA), 6))
tb_baye$mod[[1]] <- brm(Y ~ X, data = tb, family = gaussian, chains = 2, cores = 2, iter = 10000, thin = 10, seed = 123, control = list(adapt_delta = 0.95))
tb_baye$mod[[2]] <- brm(Y1 ~ X, data = tb, family = bernoulli, chains = 2, cores = 2, iter = 10000, thin = 10, seed = 123, control = list(adapt_delta = 0.95))
tb_baye$mod[[3]] <- brm(Y2 ~ X, data = tb, family = poisson, chains = 2, cores = 2, iter = 10000, thin = 10, seed = 123, control = list(adapt_delta = 0.95))
tb_baye$mod[[4]] <- brm(Y3 ~ X, data = tb, family = negbinomial, chains = 2, cores = 2, iter = 10000, thin = 10, seed = 123, control = list(adapt_delta = 0.95))
tb_baye$mod[[5]] <- brm(bf(Y4 ~ X, zi ~ 1), data = tb, family = zero_inflated_poisson, chains = 2, cores = 2, iter = 10000, thin = 10, seed = 123, control = list(adapt_delta = 0.95))
tb_baye$mod[[6]] <- brm(bf(Y5 ~ X, zi ~ 1), data = tb, family = zero_inflated_negbinomial, chains = 2, cores = 2, iter = 10000, thin = 10, seed = 123, control = list(adapt_delta = 0.95))

# Extract observed response generically
.get_y <- function(mod) {
    model.response(model.frame(mod))
}

# 2) Empirical R2 computed from posterior draws (matches bayes_R2 logic)
#    R2_draw = Var(mu_draw) / ( Var(mu_draw) + Var(y - mu_draw) )
r2_from_draws <- function(mod, ndraws = NULL) {
    mu <- posterior_epred(mod, ndraws = ndraws)  # draws x N; on response scale; includes ZI if any
    y  <- .get_y(mod)

    var_mu   <- apply(mu, 1, var)
    var_res  <- apply(mu, 1, function(m) var(y - m))
    r2_draws <- var_mu / (var_mu + var_res)

    tibble(
        mean   = mean(r2_draws),
        sd     = sd(r2_draws),
        q2.5   = quantile(r2_draws, 0.025),
        q50    = quantile(r2_draws, 0.50),
        q97.5  = quantile(r2_draws, 0.975)
    )
}

# Variance and bayesian R2, which is computed at the latent scale
## Gaussian
pp_check(tb_baye$mod[[1]])
r2_from_draws(tb_baye$mod[[1]])
bayes_R2(tb_baye$mod[[1]])

## Logistic
pp_check(tb_baye$mod[[2]])
r2_from_draws(tb_baye$mod[[2]])
bayes_R2(tb_baye$mod[[2]])

## Poisson
pp_check(tb_baye$mod[[3]])
r2_from_draws(tb_baye$mod[[3]])
bayes_R2(tb_baye$mod[[3]])

## Negative binomial
pp_check(tb_baye$mod[[4]])
as_draws_df(tb_baye$mod[[4]])$shape %>% median # estimated dispersion parameter
r2_from_draws(tb_baye$mod[[4]])
bayes_R2(tb_baye$mod[[4]])

## ZIP
pp_check(tb_baye$mod[[5]])
tb_baye$mod[[5]]
z <- as_draws_df(tb_baye$mod[[5]])$Intercept_zi
(exp(z) / (1+exp(z))) %>% mean # probability of an observation to be structurally zero
r2_from_draws(tb_baye$mod[[5]])
bayes_R2(tb_baye$mod[[5]])

## ZINB
pp_check(tb_baye$mod[[6]])
tb_baye$mod[[6]]
as_draws_df(tb_baye$mod[[6]])$shape %>% median # estimated dispersion parameter
z <- as_draws_df(tb_baye$mod[[6]])$Intercept_zi
(exp(z) / (1+exp(z))) %>% mean # probability of an observation to be structurally zero
r2_from_draws(tb_baye$mod[[6]])
bayes_R2(tb_baye$mod[[6]])
